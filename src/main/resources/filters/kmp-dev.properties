spark.master=spark.master=local[*]
spark.streaming.concurrentJobs=20
spark.default.parallelism=32
spark.executor.extraJavaOptions=-XX:NewRatio=1 -XX:SurvivorRatio=8 -XX:+UseCompressedOops -XX:SoftRefLRUPolicyMSPerMB=0 -XX:MaxPermSize=512m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/apps/logs/spark/
spark.kryoserializer.buffer.mb=20
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.speculation=true
spark.storage.memoryFraction=0.3

spark.executor.logs.rolling.strategy=time
spark.executor.logs.rolling.time.interval=daily
spark.executor.logs.rolling.maxRetainedFiles=3

kafkareceiver.group.id=KMPG_AM
kafkareceiver.zookeeper.connect=192.168.254.130:2181
kafkareceiver.zookeeper.session.timeout.ms=30000
kafkareceiver.zookeeper.sync.time.ms=200
kafkareceiver.auto.commit.interval.ms=1000
kafkareceiver.rebalance.backoff.ms=10000

kafka.topics=accessview_log_test
kafka.topic.partition.counts=1

kafka.receiver.count=1
kafka.receiver.consumer.count=1
kmp.application.name=KMP-AM
kmp.repartition.num=2

kmp.spark.streaming.duration=60000
kmp.spark.streaming.window_duration=60000
kmp.spark.streaming.slide_duration=60000

kmp.cache.page.size=10
kmp.cache.cleanup.during=1000
kmp.cache.remove.cleanup.during=1000
kmp.cache.hotdata.limit.size=3
kmp.cache.limit.size=3
kmp.cache.check_cache_size.during=1000

kmp.jdbc.url=jdbc:mysql://192.168.254.1/access_view
kmp.jdbc.driver=com.mysql.jdbc.Driver
kmp.jdbc.username=root
kmp.jdbc.password=123456